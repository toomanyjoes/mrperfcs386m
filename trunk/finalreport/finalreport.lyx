#LyX 1.6.4 created this file. For more info see http://www.lyx.org/
\lyxformat 345
\begin_document
\begin_header
\textclass article
\begin_preamble
%% LyX 1.6.4 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.



\usepackage[letterpaper]{geometry}

\geometry{verbose,tmargin=1in,bmargin=1in,lmargin=0.75in,rmargin=0.75in}
\end_preamble
\options twocolumn
\use_default_options false
\language english
\inputencoding latin9
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 0
\use_esint 0
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\author "" 
\end_header

\begin_body

\begin_layout Title
Edge-Based Cloud Computing as a Feasible Network Paradigm
\end_layout

\begin_layout Author
Joe Elizondo and Samuel Palmer 
\begin_inset Newline newline
\end_inset

 Department of Computer Science University of Texas at Austin
\begin_inset Newline newline
\end_inset

 Email: {elizondo, spalmer}@cs.utexas.edu 
\end_layout

\begin_layout Abstract
Abstract 
\end_layout

\begin_layout Section
Introduction 
\end_layout

\begin_layout Standard
Edge based cloud computing is a combination of two popular ideas, edge computing
 and cloud computing.
 We believe that the combination of these two ideas offers the potential
 for a high performance per dollar ratio by leveraging the enormous amount
 of unused computational power in idle home computer processors that have
 access to always-on internet connections.
 Despite its potential this type of computing paradigm is not being used
 and is only sparsely investigated.
 This paper will present the results of our research on edge based cloud
 computing and some of the benefits and challenges we discovered through
 our work.
 In order to determine the full potential of this non-existent network we
 use simulation and run MapReduce jobs that push the network beyond the
 usual peer-to-peer/grid computing type simple data transfer that these
 topologies are commonly used for.
 MapReduce operations involve a high level of coordination and communication
 between machines in addition to transferring large amounts of data.
 For our simulation environment we investigate MRPerf, a MapReduce tool
 built on top of the network simulator ns-2, which was developed by researchers
 at Virginia Tech and IBM Almaden Research Center.
 To simulate an edge based network we will change the parameters in our
 configuration to better mimic a peer-to-peer type system of nodes without
 central infrastructure.
 Each node has fewer resources and is located at a further distance from
 one another than nodes in a data center.
 We also customize our simulation settings to account for sluggish nodes
 and node churn.
 Our final report will probably have a structure similar to the following.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Related-Work"

\end_inset

 we will discuss some related work, section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Tools"

\end_inset

 we will present an overview of the tools used, section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Simulation-Design"

\end_inset

 we will talk about some of the challenges we faced in designing our simulation,
 section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Implementation"

\end_inset

 we discuss our implementation, section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Experiments-and-Results"

\end_inset

 we will discuss some experiments and results, section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Conclusions"

\end_inset

 we will present some conclusions, and section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Future-Research"

\end_inset

 we will talk about potential future research in this area.
\end_layout

\begin_layout Section
Related Work
\begin_inset CommandInset label
LatexCommand label
name "sec:Related-Work"

\end_inset


\end_layout

\begin_layout Standard
So far we have found related work in this area to be sparse and we are still
 looking into any papers published on edge-based cloud computing; however,
 it is evident that this area is still in a stage of early development.
 Because of this our work will focus more on the feasibility of this type
 of infrastructure from the aspect of performance and in doing so we will
 ignore many practical issues such as security and privacy.
\end_layout

\begin_layout Section
Tools
\begin_inset CommandInset label
LatexCommand label
name "sec:Tools"

\end_inset


\end_layout

\begin_layout Standard
We used two main tools for our simulation.
 The most useful tool of the two being MRPerf 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang09LSAP,Wang09MASCOTS,WangREADME"

\end_inset

.
 This tool was designed to simulate MapReduce jobs when provided with a
 network topology.
 MRPerf can measure the performance of these MapReduce jobs with a good
 amount of accuracy and deliver performance information to the user.
 We also used the now unsupported Boston University Representative Internet
 Topology Generator (BRITE)
\begin_inset CommandInset citation
LatexCommand cite
key "Medina01"

\end_inset

 to generate our preliminary network topologies.
 Brite produces TCL code the represents a network based on user defined
 input parameters.
\end_layout

\begin_layout Subsection
MRPerf
\begin_inset CommandInset label
LatexCommand label
name "sub:MRPerf"

\end_inset


\end_layout

\begin_layout Standard
We chose to use MRPerf because of its impressive implementation of MapReduce
 and the accuracy of its simulation results.
 Our research involves testing an edge computing network with demanding
 highly coordinated applications.
 MapReduce is a good tool for testing this because its design requires participa
ting machines to break up a computationally intensive job into separate
 tasks, requiring complex scheduling algorithms, process the tasks, and
 then merge them back together upon completion.
 MRPerf was build on top of two popular packages, ns-2
\begin_inset CommandInset citation
LatexCommand cite
key "Fall"

\end_inset

 and hadoop
\begin_inset CommandInset citation
LatexCommand cite
key "Hadoop"

\end_inset

.
 MRPerf merges MapReduce and network simulation to achieve a seamless simulation
 environment.
 MRPerf claims to have the ability to simulate a wide range of network topologie
s and also has the ability to evaluate the performance of MapReduce operations
 on that network.
 MRPerf was originally designed for use in a data center type infrastructure.
 With that in consideration, MRPerf claims to predict simulation performance
 within 5.22% of actual measurements for map and 12.83% for reduce for a double
 rack cluster with 16 to 128 cores
\begin_inset CommandInset citation
LatexCommand cite
key "Wang09MASCOTS"

\end_inset

.
\end_layout

\begin_layout Subsection
BRITE
\begin_inset CommandInset label
LatexCommand label
name "sub:BRITE"

\end_inset


\end_layout

\begin_layout Standard
We wanted to run our simulation on a fairly large network to get an accurate
 idea of performance when route scheduling, node churn, and link latency
 are all taken into consideration.
 The hand generation of this type of network quickly grew beyond our ability.
 Because of this we employed a tool to create a network topology based on
 the parameters that we provide.
 BRITE creates a random set of nodes and routers based on two different
 probability models, Waxman and Barab√°si-Albert 
\begin_inset CommandInset citation
LatexCommand cite
key "Medina01"

\end_inset

.
 Some of the more important parameters we made use of were the max/min link
 speeds, number of nodes, maximum out-degree of nodes, and random or incremental
 node growth.
\end_layout

\begin_layout Section
Simulation Design 
\begin_inset CommandInset label
LatexCommand label
name "sec:Simulation-Design"

\end_inset


\end_layout

\begin_layout Standard
The accuracy of the results in our simulation rely heavily on the accurate
 representation of the edge computing network topology we create.
 Once we have a network that we are content with we can pass the topology
 to MRPerf and rely on their system to give us accurate feedback on performance.
 To build a accurate representation of our network we have to be familiar
 with the parameters that MRPerf uses throughout the simulation process.
 MRPerf implements MapReduce based on three classes of parameters: cluster
 parameters, configuration parameters, and framework parameters.
 To represent our network we must change the default assumptions that MRPerf
 makes about the network infrastructure and in many cases make some customizatio
ns directly to the python code.
\end_layout

\begin_layout Subsection
Cluster Parameters
\begin_inset CommandInset label
LatexCommand label
name "sub:Cluster-Parameters"

\end_inset


\end_layout

\begin_layout Standard
MRPerf is designed to work with a data center using racks which consist
 of many nodes that are close to each other on the network, this means that
 a packet many times is just one hop away from its destination.
 These racks of nodes are connected together to form a cluster.
 In an edge computing network there is no concept of a centralized cluster
 of computational power.
 Edge computing networks use PCs that are connected to the internet via
 a LAN through a router or gateway.
 This means that a packet's destination is almost always several network
 hops away.
 The racks that make up a cluster have many compute nodes each of which
 have several processors whereas a PC in an edge network has anywhere from
 one to four processors.
 Another difference in the cluster parameters is related to node heterogeneity.
 A data center setup has homogeneous nodes, whereas in an edge network nodes
 have a high level of heterogeneity.
 The interconnect topologies also play a role in the cluster parameters.
 The inter/intra-rack topology of a data center is much less complex than
 the internet.
\end_layout

\begin_layout Subsection
Configuration Parameters
\begin_inset CommandInset label
LatexCommand label
name "sub:Configuration-Parameters"

\end_inset


\end_layout

\begin_layout Standard
Configuration parameters are related to the MapReduce jobs themselves.
 They adjust settings such as data chuck size, data replication, tasks per
 node, and tasks in each job.
 All of these settings are optimized for a data center by default.
 Some of the changes we have to make will depend upon the optimal configuration
 of an edge computing network.
 Whether data chunk size is large or small depends upon whether an edge
 computing system performs better when I/O is optimized or when parallelism
 in increased.
 The cost of data replication is clearly higher in an edge computing network
 than in a data center, however our experiments attempt to discover the
 optimal amount of replication among nodes.
\end_layout

\begin_layout Subsection
Framework Parameters
\begin_inset CommandInset label
LatexCommand label
name "sub:Framework-Parameters"

\end_inset


\end_layout

\begin_layout Standard
Framework parameters deal with data placement and scheduling algorithms.
 The distance of nodes relative the machine requesting jobs needs to be
 considered when partitioning data across available resources.
 In a data center with many compute nodes the wrong choice of data placement
 can affect performance to a degree, but is not nearly as costly as the
 wrong choice when compute nodes could potentially be in a different country.
 MRPerf compares three types of data locality, node-local, rack-local, rack-remo
te.
 Our data placement algorithm will be similar to their rack remote setup,
 which is the slowest for all tests run 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang09MASCOTS"

\end_inset

.
 Scheduling will also need to be adjusted to optimize job scheduling for
 the internet rather than a data center.
 Changes to these algorithms require a good amount of customization to the
 MRPerf source code.
 As discussed above the proper balance of data chunk size, data placement,
 and task scheduling are important so that the system does not suffer huge
 performance losses transferring large amounts of data over relatively slow
 links to a non-optimal number of nodes.
\end_layout

\begin_layout Subsection
Limitations
\begin_inset CommandInset label
LatexCommand label
name "sub:Limitations"

\end_inset


\end_layout

\begin_layout Standard
There are a couple of limitations that are inherent when working with MRPerf
 that are worth discussing.
 These limitations are related to disk storage and node reliability.
 The former works to our advantage in this case.
 MRPerf only allows for one single storage device per node.
 In a data center this might be an unusual constraint however since the
 average PC that constitutes our edge computing network will have only a
 single storage disk this should not present a problem in our experiments.
 The other limitation, left unhandled, could indeed skew our results to
 the positive.
 MRPerf, though it allows for single node and link failures, doesn't support
 lagging or partially failing nodes.
 An accurate representation of a network for our simulation requires that
 some nodes lag when given a job.
 In this case our scheduling algorithm will have to compensate for this
 deficiency.
 By having a larger amount of failing nodes we can simulate a scheduling
 algorithm that treats a lagging node as a fully failing node.
 In this case a failing node in our simulation could also represent a node
 that operates below a certain performance threshold whose job the scheduler
 kills and gives to another node.
\end_layout

\begin_layout Subsection
Other Challenges
\begin_inset CommandInset label
LatexCommand label
name "sub:Other-Challenges"

\end_inset


\end_layout

\begin_layout Standard
Other challenges include the fact that this type of network topology is
 non-existent.
 None of our performance results, at this time can, be compared with similar
 tests on an actual system.
\end_layout

\begin_layout Section
Implementation
\begin_inset CommandInset label
LatexCommand label
name "sec:Implementation"

\end_inset


\end_layout

\begin_layout Standard
To configure MRPerf for our simulation purposes we had to address all of
 the issues discussed in the previous section.
 These issue arise because of the significant differences between our research
 and MRPerf's default assumptions.
 These different assumptions are present because MRPerf was designed to
 work with a data center type architecture with a centralized infrastructure.
 Without modifications any tests run would simulate a multi-rack data center
 with many nodes per rack and high bandwidth single hop links connecting
 them together.
 However MRPerf allows some flexibility since it was built on top of the
 ns-2 network simulator.
 Because of this any topology supported by ns-2 is also supported by MRPerf.
 ns-2 has been used to simulate all types of networks including grid computing
 and peer to peer type topologies 
\begin_inset CommandInset citation
LatexCommand cite
key "Kun05,Zegura96"

\end_inset

 that our network closely resembles.
 By using a topology generating tool, discussed in section 3, we create
 a large topology for our simulation purposes and pass that in to MRPerf.
 We then send MapReduce jobs to our network using MRPerf.
 By default MRPerf expects the topology to be in XML format.
 While this format makes simple additions more convenient it also makes
 simulating a network of tens of thousands of nodes a chore to create.
 Because of this we bypass the MRPerf's XML translator and have our topology
 generator create our topology directly in TCL.
 The implementation challenges (section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Simulation-Design"

\end_inset

) arise almost entirely in creating an accurate representation of the edge
 computing network.
 Topology generators are a good starting point for us but we must adjust
 many parameters and customize a good portion of the source code for our
 system to faithfully represent actual performance results.
 Some parameters we adjust are the link speeds and latency for each edge
 router as well as the link speed and latency for the network backbone.
 Router connectivity is also important to get correct for an accurate simulation.
 The bulk of our ongoing research is in this area and we plan to have more
 to report as we test our implementation.
 We have provided a small preliminary visualization of a subnet in our network
 topology, Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Preliminary-Topology-Visualization"

\end_inset

.
 Routers are represented as black circles and compute nodes as green squares.
 The node initializing the job request is labeled 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
textquotedbl
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{}
\end_layout

\end_inset

JT
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
textquotedbl
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{}
\end_layout

\end_inset

 (job tracker).
 The thicker black lines parallel to the link lines represent a flow of
 packets through the link.
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="9" columns="2">
<features>
<column alignment="center" valignment="middle" width="2.6cm">
<column alignment="center" valignment="middle" width="5cm">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CPU speed (GHz) 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.5, 1.6, 1.8, 2.0, 2.3, 2.4, 2.5, 3.0, 3.2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Number of CPUs
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1, 2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Number of cores per CPU
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1, 2, 4
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Number of disks
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1, 2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Disk capacity (GB)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
40, 60, 80, 100, 120, 160, 180, 200, 250, 300, 400, 450, 500, 550, 600,
 650, 700, 750, 800, 850, 900, 950, 1000
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Disk read bandwidth (MB/s)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
250, 260, 270, 280
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Disk write bandwidth (MB/s)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
60, 65, 70, 75
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
NIC capacity
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
100Mbps, 1Gbps
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Memory capacity (GB)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.5, 1, 2, 3, 4, 5, 6
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Summary of ranges used in host specification
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename prelim-visual.png
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Preliminary Topology Visualization
\begin_inset CommandInset label
LatexCommand label
name "fig:Preliminary-Topology-Visualization"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Experiments and Results
\begin_inset CommandInset label
LatexCommand label
name "sec:Experiments-and-Results"

\end_inset


\end_layout

\begin_layout Standard
We conducted experiments in which we varied several aspects of the simulation
 including the number of nodes, chunk size, and the number of mapper and
 reducer slots per node.
 The results presented in this section are the average over five experiments
 with the same parameters but different seeds for our pseudo-random number
 generator.
 All of the hosts in the edge experiments All statistically insignificant
 data points have been removed.
 For the chunk size experiments we conducted two types of experiments, one
 in which the nodes are in a double rack data center and one in which nodes
 are randomly distributed throughout the mapped portion of the Internet.
 For both types we used 50 node topologies which we held constant for all
 experiments.
 Results for these experiments are presented in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:chunkSize"

\end_inset

.
\end_layout

\begin_layout Standard
For experiments in which we varied the number of mapper and reducer slots
 per node we used a chunk size of 6 MB and a 50 node topology randomly distribut
ed across the mapped portion of the Internet.
 The topology was held constant as we varied the number of mapper and reducer
 slots.
 The results of this experiment is presented in Figure 

\begin_inset CommandInset ref
LatexCommand ref
reference "fig:mapperReducer"

\end_inset


\lang english
.
\end_layout

\begin_layout Standard
We ran three types of experiments that varied the number of nodes.
 We varied the number of nodes in a double rack data center, distributed
 across the mapped portion of the Internet, and distributed across one autonomou
s system consisting of 15 mapped routers which span the United States.
 Each consecutive experiment for the edge based data kept the previous experimen
t's topology and added 10 additional nodes randomly distributed throughout
 the topology.
 The results for the data center and edge based experiments are presented
 in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:dataCenterNumHosts"

\end_inset

, Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:numHosts"

\end_inset

 and Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:numHosts_oneAS"

\end_inset

.
\end_layout

\begin_layout Standard
\align left
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align left
\begin_inset Graphics
	filename results/results_dataCenterChunkSizeBoth.png
	width 8.7cm

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
Results for 50 node topologies in a double rack data center configuration
 (a) and a random configuration distributed across the entire mapped portion
 of the Internet (b) in which the size of the data chunks was variable.
\begin_inset CommandInset label
LatexCommand label
name "fig:chunkSize"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename results/results_mapperReducer_shaded.png
	width 8.7cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Results for a 50 node topology randomly distributed across the mapped portion
 of the Internet in which the number of map and reduce slots available on
 each host was variable.
\begin_inset CommandInset label
LatexCommand label
name "fig:mapperReducer"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename results/results_dataCenterNumHosts.png
	width 8.7cm

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
Results for double rack data center topologies in which the total number
 of nodes was variable.
\begin_inset CommandInset label
LatexCommand label
name "fig:dataCenterNumHosts"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename results/results_numHosts.png
	width 8.7cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Results for topologies in which each consecutive point represents the running
 time when 10 additional hosts are randomly added to the previous topology.
 Hosts are distributed across the entire mapped portion of the Internet.
\begin_inset CommandInset label
LatexCommand label
name "fig:numHosts"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename results/results_numHosts_oneAS.png
	width 8.7cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Results for topologies in which each consecutive point represents the running
 time when 10 additional hosts are randomly added to the previous topology.
 Hosts are distributed across AS 11537 which spans the entire United States
 and parts of southern Canada.
\begin_inset CommandInset label
LatexCommand label
name "fig:numHosts_oneAS"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Conclusions
\begin_inset CommandInset label
LatexCommand label
name "sec:Conclusions"

\end_inset


\end_layout

\begin_layout Standard
This section will discuss the conclusions that we've reached through our
 research.
\end_layout

\begin_layout Section
Future Research
\begin_inset CommandInset label
LatexCommand label
name "sec:Future-Research"

\end_inset


\end_layout

\begin_layout Standard
Another simulation tool that could be used to gather performance results
 of a edge-based cloud computing network is CloudSim.
 Future research could involve investigating the use of MapReduce with this
 Java based simulation tool that has recently been developed 
\begin_inset CommandInset citation
LatexCommand cite
key "Buyya09,Rose09"

\end_inset

.
 CloudSim was built on top of the existing tools, JavaSim and GridSim, which
 have already proven themselves valid for simulation.
 CloudSim itself is an effort to add a new layer of features on top of these
 tools that are more critical and immediately relevant to cloud computing.
 By abstracting away all the lower levels CloudSim can focus on doing its
 job correctly and at the same time trust that the layers below are functioning
 correctly as well.
 The results gathered from simulation with this tool would be a valuable
 comparison to the results we present in this paper.
 Other avenues for research could address the security and privacy implications
 for this type of computing paradigm.
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
bibliographystyle{acm}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
nocite{*}
\end_layout

\end_inset

 
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintAll"
bibfiles "finalreport"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
